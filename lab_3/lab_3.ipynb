{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4904799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "\n",
    "from segmentation_dataset import SegmentationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model properties\n",
    "NUMBER_OF_CLASSES = 4\n",
    "CLASSES = ['Cat', 'Horse', 'Pizza']\n",
    "ROOT_DATA_DIRECTORY = Path(\"segmentation_data\")\n",
    "BATCH_SIZE = 16\n",
    "NUMBER_OF_TRAIN_WORKERS = 4\n",
    "IN_CHANNELS = 3\n",
    "OUT_CHANNELS = 4\n",
    "FEATURES = [32, 64, 128, 256]\n",
    "\n",
    "LABELS = {\n",
    "    \"Background\":0,\n",
    "    \"Cat\": 1,\n",
    "    \"Horse\": 2,\n",
    "    \"Pizza\": 3,\n",
    "}\n",
    "REVERSE_LABELS = {value: key for key, value in LABELS.items()}\n",
    "\n",
    "\n",
    "COLOURS = {\n",
    "    0: (0, 0, 0),\n",
    "    1: (53, 94, 59),\n",
    "    2: (150, 75, 0),\n",
    "    3: (176,224,230),\n",
    "}\n",
    "\n",
    "REVERSE_COLOURS = {\n",
    "    value: key for key, value in COLOURS.items()\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train properties\n",
    "NUMBER_OF_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "NUMBER_OF_TRAIN_IMAGES_PER_CLASS = 1000\n",
    "NUMBER_OF_VALIDATION_IMAGES_PER_CLASS = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test properties\n",
    "NUMBER_OF_TEST_IMAGES_PER_CLASS = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images\n",
    "def load_images(root_directory:str, class_name: str, split: str, size: int) -> None:\n",
    "    dataset = foz.load_zoo_dataset(\n",
    "        \"open-images-v6\",\n",
    "        split=split,\n",
    "        label_types=[\"segmentations\"],\n",
    "        classes=[class_name],\n",
    "        max_samples=size,\n",
    "        dataset_name=f\"open-images-{split}-{class_name.lower()}-segmentation\",\n",
    "    )\n",
    "    for sample in dataset:\n",
    "        detections = [\n",
    "            d for d in sample.ground_truth.detections if d.label == class_name\n",
    "        ]\n",
    "\n",
    "        sample.ground_truth.detections = detections\n",
    "        sample.save()\n",
    "\n",
    "    dataset.export(\n",
    "        export_dir=f\"{root_directory}/{split}/{class_name}\",\n",
    "        dataset_type=fo.types.ImageSegmentationDirectory,\n",
    "        label_field=\"ground_truth\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1389cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images by class\n",
    "for class_name in CLASSES:\n",
    "    load_images(root_directory=ROOT_DATA_DIRECTORY, class_name=class_name, split=\"train\", size=NUMBER_OF_TRAIN_IMAGES_PER_CLASS)\n",
    "    load_images(root_directory=ROOT_DATA_DIRECTORY, class_name=class_name, split=\"validation\", size=NUMBER_OF_VALIDATION_IMAGES_PER_CLASS)\n",
    "    load_images(root_directory=ROOT_DATA_DIRECTORY, class_name=class_name, split=\"test\", size=NUMBER_OF_TEST_IMAGES_PER_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da2e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coloured_masks_for_each_class(\n",
    "    classes: list[str],\n",
    "    label_map: dict[str, int],\n",
    "    colour_map: dict[int, tuple[int, int, int]],\n",
    "    root_directory: Path,\n",
    "    split: str\n",
    ") -> None:\n",
    "    for class_name in classes:\n",
    "        class_mask_dir = root_directory / split / class_name / \"labels\"\n",
    "        class_coloured_dir = root_directory / split / class_name / \"coloured_labels\"\n",
    "        class_coloured_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        class_id = label_map[class_name]\n",
    "        class_color = colour_map[class_id]\n",
    "\n",
    "        for mask_path in class_mask_dir.glob(\"*.png\"):\n",
    "            binary_mask = Image.open(mask_path).convert(\"L\")\n",
    "            mask_array = np.array(binary_mask) > 127\n",
    "\n",
    "            height, width = mask_array.shape\n",
    "            coloured_mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "            coloured_mask[mask_array] = class_color\n",
    "\n",
    "            out_path = class_coloured_dir / mask_path.name\n",
    "            Image.fromarray(coloured_mask).save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d58239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create multiclass masks\n",
    "create_coloured_masks_for_each_class(classes=CLASSES, label_map=LABELS, colour_map=COLOURS, root_directory=ROOT_DATA_DIRECTORY, split=\"train\")\n",
    "create_coloured_masks_for_each_class(classes=CLASSES, label_map=LABELS, colour_map=COLOURS, root_directory=ROOT_DATA_DIRECTORY, split=\"validation\")\n",
    "create_coloured_masks_for_each_class(classes=CLASSES, label_map=LABELS, colour_map=COLOURS, root_directory=ROOT_DATA_DIRECTORY, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate normalization values for train dataset\n",
    "normalization_image_directories = [ROOT_DATA_DIRECTORY / \"train\" / class_name / \"data\" for class_name in CLASSES]\n",
    "\n",
    "channels_sum = torch.zeros(3)\n",
    "channels_square_sum = torch.zeros(3)\n",
    "total_pixels = 0\n",
    "\n",
    "for image_directory in normalization_image_directories:\n",
    "    for image_path in image_directory.rglob(\"*\"):\n",
    "        with Image.open(image_path).convert(\"RGB\") as img:\n",
    "            image_tensor = torch.from_numpy(np.array(img)).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        channels_sum += image_tensor.sum(dim=[1, 2])\n",
    "        channels_square_sum += (image_tensor ** 2).sum(dim=[1, 2])\n",
    "\n",
    "        height, width = image_tensor.shape[1], image_tensor.shape[2]\n",
    "        total_pixels += height * width\n",
    "\n",
    "mean = channels_sum / total_pixels\n",
    "var = (channels_square_sum / total_pixels) - mean**2\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"STD:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e79317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated values are assigned manually to avoid recalculation\n",
    "NORMALIZATION_MEAN = [0.4965, 0.4356, 0.3669]\n",
    "NORMALIZATION_STD = [0.2757, 0.2691, 0.2757]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7cad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationConvolutionalNetwork(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, features: list[int]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.pool_layer = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.down_layers = torch.nn.ModuleList()\n",
    "        current_in_channels = in_channels\n",
    "        for feature in features:\n",
    "            self.down_layers.append(\n",
    "                SegmentationConvolutionalNetwork.double_convolution(\n",
    "                    in_channels=current_in_channels,\n",
    "                    out_channels=feature\n",
    "                )\n",
    "            )\n",
    "            current_in_channels = feature\n",
    "        \n",
    "        self.bottleneck_layer = SegmentationConvolutionalNetwork.double_convolution(in_channels=features[-1], out_channels=features[-1]*2)\n",
    "\n",
    "        self.up_layers = torch.nn.ModuleList()\n",
    "        current_in_channels = features[-1] * 2\n",
    "        for feature in reversed(features):\n",
    "            self.up_layers.append(\n",
    "                torch.nn.ConvTranspose2d(\n",
    "                    in_channels=current_in_channels,\n",
    "                    out_channels=feature,\n",
    "                    kernel_size=2,\n",
    "                    stride=2\n",
    "                )\n",
    "            )\n",
    "            self.up_layers.append(\n",
    "                SegmentationConvolutionalNetwork.double_convolution(\n",
    "                    in_channels=feature * 2,\n",
    "                    out_channels=feature\n",
    "                )\n",
    "            )\n",
    "            current_in_channels = feature\n",
    "\n",
    "        self.final_convolution = torch.nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def double_convolution(cls, in_channels: int, out_channels: int):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(num_features=out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(num_features=out_channels),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        skip_connections = []\n",
    "\n",
    "        out = x\n",
    "\n",
    "        for down_layer in self.down_layers:\n",
    "            out = down_layer(out)\n",
    "            skip_connections.append(out)\n",
    "            out = self.pool_layer(out)\n",
    "        \n",
    "        out = self.bottleneck_layer(out)\n",
    "\n",
    "        reversed_skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for layer_id in range(0, len(self.up_layers), 2):\n",
    "            transposed_convolution = self.up_layers[layer_id]\n",
    "            out = transposed_convolution(out)\n",
    "\n",
    "            skip_out = reversed_skip_connections[layer_id // 2]\n",
    "\n",
    "            if out.shape != skip_out.shape:\n",
    "                out = torch.nn.functional.interpolate(out, size=skip_out.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "            out = torch.cat([skip_out, out], dim=1)\n",
    "\n",
    "            out = self.up_layers[layer_id + 1](out)\n",
    "        \n",
    "        out = self.final_convolution(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize train device\n",
    "train_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(train_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4256279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize train model\n",
    "train_model = SegmentationConvolutionalNetwork(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS, features=FEATURES)\n",
    "train_model.to(train_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validation datasets\n",
    "train_dataset = SegmentationDataset(classes=CLASSES, root_directory=ROOT_DATA_DIRECTORY, mode=\"train\", reverse_colours=REVERSE_COLOURS, normalization_mean=NORMALIZATION_MEAN, normalization_std=NORMALIZATION_STD)\n",
    "validation_dataset = SegmentationDataset(classes=CLASSES, root_directory=ROOT_DATA_DIRECTORY, mode=\"validation\", reverse_colours=REVERSE_COLOURS, normalization_mean=NORMALIZATION_MEAN, normalization_std=NORMALIZATION_STD)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=NUMBER_OF_TRAIN_WORKERS, shuffle=True)\n",
    "validation_dataloader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1, num_workers=NUMBER_OF_TRAIN_WORKERS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1176cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_iou(preds:torch.Tensor, labels: torch.Tensor, number_of_classes:int) -> float:\n",
    "    if preds.dim() == 4 and preds.size(1) > 1:\n",
    "        preds = preds.argmax(dim=1) \n",
    "    \n",
    "    preds_flat = preds.view(-1)\n",
    "    labels_flat = labels.view(-1)\n",
    "\n",
    "    ious = []\n",
    "    for class_index in range(number_of_classes):\n",
    "        class_predictions = (preds_flat == class_index)\n",
    "        class_labels = (labels_flat == class_index)\n",
    "\n",
    "        intersection = (class_predictions & class_labels).sum().item()\n",
    "        union = (class_predictions | class_labels).sum().item()\n",
    "\n",
    "        if union == 0:\n",
    "            continue\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "\n",
    "    if len(ious) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return np.mean(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243623a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.smooth = 1e-6\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        probs = torch.nn.functional.softmax(inputs, dim=1)\n",
    "        targets_one_hot = torch.nn.functional.one_hot(targets, num_classes=self.num_classes)\n",
    "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2).float()\n",
    "\n",
    "        probs_flat = probs.view(probs.size(0), probs.size(1), -1)\n",
    "        targets_flat = targets_one_hot.view(targets_one_hot.size(0), targets_one_hot.size(1), -1)\n",
    "\n",
    "        intersection = (probs_flat * targets_flat).sum(dim=2)\n",
    "        cardinality = (probs_flat + targets_flat).sum(dim=2)\n",
    "\n",
    "        dice_score = ((2 * intersection + self.smooth) / (cardinality + self.smooth)).mean(dim=0)\n",
    "\n",
    "        dice_score_mean = dice_score.mean()\n",
    "\n",
    "        dice_loss = 1 - dice_score_mean\n",
    "\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "train_losses = np.zeros(NUMBER_OF_EPOCHS)\n",
    "validation_losses = np.zeros(NUMBER_OF_EPOCHS)\n",
    "\n",
    "train_ious = np.zeros(NUMBER_OF_EPOCHS)\n",
    "validation_ious = np.zeros(NUMBER_OF_EPOCHS)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(params=train_model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "\n",
    "loss_function_ce = torch.nn.CrossEntropyLoss()\n",
    "loss_function_dice = DiceLoss(num_classes=NUMBER_OF_CLASSES)\n",
    "\n",
    "ce_weight = 0.5\n",
    "dice_weight = 0.5\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',    \n",
    "    factor=0.1,    \n",
    "    patience=3,     \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    train_loss_acum = np.array([], dtype = np.float32)\n",
    "    validation_loss_acum = np.array([], dtype = np.float32)\n",
    "\n",
    "    train_iou_acum = np.array([], dtype = np.float32)\n",
    "    validation_iou_acum = np.array([], dtype = np.float32)\n",
    "\n",
    "    train_model.train()\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(train_device)\n",
    "        labels = labels.to(train_device)\n",
    "\n",
    "        predictions = train_model(images)\n",
    "        ce_loss_train = loss_function_ce(predictions, labels)\n",
    "        dice_loss_train = loss_function_dice(predictions, labels)\n",
    "        total_loss_train = ce_weight * ce_loss_train + dice_weight * dice_loss_train\n",
    "        train_loss_acum = np.append(train_loss_acum, total_loss_train.cpu().detach().numpy())\n",
    "\n",
    "        total_loss_train.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        iou_batch = compute_mean_iou(predictions.detach(), labels, number_of_classes=NUMBER_OF_CLASSES)\n",
    "        train_iou_acum = np.append(train_iou_acum, iou_batch)\n",
    "\n",
    "    train_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_dataloader:\n",
    "            images = images.to(train_device)\n",
    "            labels = labels.to(train_device)\n",
    "\n",
    "            predictions = train_model(images)\n",
    "\n",
    "            ce_loss_validation = loss_function_ce(predictions, labels)\n",
    "            dice_loss_validation = loss_function_dice(predictions, labels)\n",
    "            total_loss_validation = ce_weight * ce_loss_validation + dice_weight * dice_loss_validation\n",
    "            validation_loss_acum = np.append(validation_loss_acum, total_loss_validation.cpu().detach().numpy())\n",
    "\n",
    "            iou_batch = compute_mean_iou(preds=predictions.detach(), labels=labels, number_of_classes=NUMBER_OF_CLASSES)\n",
    "            validation_iou_acum = np.append(validation_iou_acum, iou_batch)\n",
    "    \n",
    "    train_losses[epoch] = np.mean(train_loss_acum)\n",
    "    train_ious[epoch]   = np.mean(train_iou_acum)\n",
    "\n",
    "    validation_losses[epoch] = np.mean(validation_loss_acum)\n",
    "    validation_ious[epoch] = np.mean(validation_iou_acum)\n",
    "\n",
    "    scheduler.step(validation_losses[epoch])\n",
    "\n",
    "    print(f'Epoch: {epoch}, Train loss: {train_losses[epoch]} Validation loss: {validation_losses[epoch]}')\n",
    "    print(f'Epoch: {epoch}, Train IoU: {train_ious[epoch]} Validation IoU: {validation_ious[epoch]}')\n",
    "\n",
    "    torch.save(train_model.state_dict(), f\"segmentation_models4/{epoch}_segmentation_CN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and validation graphs\n",
    "epochs = np.arange(1, NUMBER_OF_EPOCHS + 1)\n",
    "\n",
    "# loss graph\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# iou graph\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(epochs, train_ious, label='Train Intersection Over Union')\n",
    "plt.plot(epochs, validation_ious, label='Validation Intersection Over Union')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Intersection Over Union')\n",
    "plt.title('Intersection Over Union over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize test device\n",
    "test_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(test_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize test model\n",
    "test_model = SegmentationConvolutionalNetwork(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS, features=FEATURES)\n",
    "test_model.load_state_dict(torch.load(\"segmentation_models3/53_segmentation_CN.pth\", weights_only=True))\n",
    "test_model.to(test_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5040b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize test dataset\n",
    "test_dataset = SegmentationDataset(classes=CLASSES, root_directory=ROOT_DATA_DIRECTORY, mode=\"test\", reverse_colours=REVERSE_COLOURS, normalization_mean=NORMALIZATION_MEAN, normalization_std=NORMALIZATION_STD)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_dice_score(y_pred: torch.Tensor, y_true:torch.Tensor, number_of_classes:int) -> tuple[list[float], float]:\n",
    "    smooth=1e-6\n",
    "    dice_per_class = []\n",
    "\n",
    "    for c in range(number_of_classes):\n",
    "        y_pred_c = (y_pred == c).astype(np.uint8)\n",
    "        y_true_c = (y_true == c).astype(np.uint8)\n",
    "\n",
    "        intersection = np.sum(y_pred_c * y_true_c)\n",
    "        union = np.sum(y_pred_c) + np.sum(y_true_c)\n",
    "\n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        dice_per_class.append(dice)\n",
    "\n",
    "    return dice_per_class, np.mean(dice_per_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(test_device)\n",
    "        labels = labels.to(test_device)\n",
    "\n",
    "        predictions = test_model(images)\n",
    "        preds = torch.argmax(predictions, dim=1)\n",
    "\n",
    "        for i in range(preds.size(0)):\n",
    "            all_preds.append(preds[i].cpu().numpy())\n",
    "            all_labels.append(labels[i].cpu().numpy())\n",
    "\n",
    "y_pred = np.concatenate([p.flatten() for p in all_preds])\n",
    "y_true = np.concatenate([l.flatten() for l in all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78716308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate statistics\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "dice_per_class, dice_macro = multiclass_dice_score(y_pred=y_pred, y_true=y_true, number_of_classes=NUMBER_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5646f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, score in enumerate(dice_per_class):\n",
    "    print(f\"Dice score for class {REVERSE_LABELS[i]}: {score}\")\n",
    "\n",
    "print(f\"Macro Dice score: {dice_macro}\")\n",
    "print(f\"F1 Micro score: {f1_micro}\")\n",
    "print(f\"F1 Macro score: {f1_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server application\n",
    "import io\n",
    "\n",
    "import fastapi\n",
    "import torch\n",
    "import torchvision\n",
    "import uvicorn\n",
    "from PIL import Image\n",
    "\n",
    "class ModelController(object):\n",
    "    def __init__(self) -> None:\n",
    "        self.prod_device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "        self.prod_model = SegmentationConvolutionalNetwork(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS, features=FEATURES)\n",
    "        self.prod_model.load_state_dict(\n",
    "            torch.load(\"segmentation_models3/53_segmentation_CN.pth\", weights_only=True)\n",
    "        )\n",
    "        self.prod_model.to(device=self.prod_device)\n",
    "        self.prod_model.eval()\n",
    "\n",
    "        self.prod_transformations = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(\n",
    "                    NORMALIZATION_MEAN, NORMALIZATION_STD\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def model_endpoint(self, image_file: fastapi.UploadFile = fastapi.File(...), ) -> fastapi.Response:\n",
    "        image_bytes = image_file.file.read()\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "        image_tensor = (\n",
    "            self.prod_transformations(image).unsqueeze(0).to(self.prod_device)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            predictions = self.prod_model(image_tensor)\n",
    "\n",
    "        predicted_classes = torch.argmax(predictions, dim=1)\n",
    "        prediction_map = predicted_classes.squeeze(0).cpu().numpy()\n",
    "        height, width = prediction_map.shape\n",
    "        mask_image_np = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "        for class_index, color in COLOURS.items():\n",
    "            mask_image_np[prediction_map == class_index] = color\n",
    "\n",
    "        mask_image_pil = Image.fromarray(mask_image_np)\n",
    "\n",
    "        buffer = io.BytesIO()\n",
    "        mask_image_pil.save(buffer, format=\"PNG\")\n",
    "        buffer.seek(0)\n",
    "\n",
    "        return fastapi.Response(content=buffer.getvalue(), media_type=\"image/png\")\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    model_controller = ModelController()\n",
    "    app = fastapi.FastAPI()\n",
    "    app.add_api_route(\n",
    "        path=\"/model\",\n",
    "        endpoint=model_controller.model_endpoint,\n",
    "        methods=[\"POST\"],\n",
    "    )\n",
    "    config = uvicorn.Config(app=app)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
