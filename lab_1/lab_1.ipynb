{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2reZxnC5BBxq"
      },
      "source": [
        "Model: RESNET50\n",
        "Classes: {Bee, Goose, Snail}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A-HX2P5EMHG",
        "outputId": "e55cca55-bc3e-45a8-bd47-4f7c76aa002b"
      },
      "outputs": [],
      "source": [
        "# install dependencies\n",
        "!pip install openimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwB3kKVU_2eW"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from openimages.download import download_dataset\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTRQRPbFBq0r"
      },
      "outputs": [],
      "source": [
        "# constants\n",
        "NUMBER_OF_SAMPLE_CLASSES = 3\n",
        "NUMBER_OF_SAMPLE_IMAGES_PER_CLASS = 350\n",
        "SAMPLE_IMAGES_ROOT_DIRECTORY = \"/sample_images\"\n",
        "IMAGENET_CLASS_INDEX_MAPPING = {\"bee\":300, \"goose\":99, \"snail\":113}\n",
        "T_VALUES = [0.5, 0.5, 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrsHV5bxH5ND"
      },
      "outputs": [],
      "source": [
        "# define a custom dataset class\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Attributes\n",
        "  ----------\n",
        "  all_images_paths: list[str]\n",
        "   contains paths of all images in the root directory\n",
        "  images_classes_by_directory: dict[str, str]\n",
        "    mapping from directory paths to their corresponding class names\n",
        "  image_label_index_mapping: dict[str, int]\n",
        "    mapping from class names to indices.\n",
        "  transform callable\n",
        "    transformation function applied to each image\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, root_image_directory: str, images_classes_by_directory: dict[str, str], image_label_index_mapping: dict[str, int], transform: callable) -> None:\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    root_image_directory: str\n",
        "      root directory with subdirectories with images.\n",
        "    images_classes_by_directory: dict[str, str]\n",
        "      mapping from directory paths to class names\n",
        "    image_label_index_mapping: dict[str, int]\n",
        "     mapping from class names to integer indices\n",
        "    transform: callable\n",
        "      transformation applied to images.\n",
        "    \"\"\"\n",
        "\n",
        "    self.all_images_paths: list[str] = [str(image_path) for image_path in Path(root_image_directory).rglob(\"*.jpg\")]\n",
        "    self.images_classes_by_directory: dict[str, str] = images_classes_by_directory\n",
        "    self.image_label_index_mapping = image_label_index_mapping\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    \"\"\"\n",
        "    Returns the total number of images in the dataset\n",
        "    \"\"\"\n",
        "\n",
        "    return len(self.all_images_paths)\n",
        "\n",
        "  def __getitem__(self, index: int) -> tuple[torch.Tensor, int]:\n",
        "    \"\"\"\n",
        "    Returns image at given index as a tuple\n",
        "    \"\"\"\n",
        "\n",
        "    image_path: str = self.all_images_paths[index]\n",
        "    image = Image.open(image_path).convert(mode=\"RGB\")\n",
        "\n",
        "    image_label = self.images_classes_by_directory[image_path.rpartition(\"/\")[0]]\n",
        "\n",
        "    return (self.transform(image), self.image_label_index_mapping[image_label])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqrsKYdjJCFf"
      },
      "outputs": [],
      "source": [
        "# class to store confusion matrix per class\n",
        "class ConfusionMatrix(object):\n",
        "  \"\"\"\n",
        "  Attributes\n",
        "  ----------\n",
        "  TP: int\n",
        "    true positives\n",
        "  TN: int\n",
        "    true negatives\n",
        "  FP:\n",
        "    false positives\n",
        "  FN:\n",
        "    false negatives\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, class_name:str, class_label_index:int, probabilities: np.ndarray, ground_truth_labels: np.ndarray, t_value: float = 0.5) -> None:\n",
        "    self.class_name = class_name\n",
        "\n",
        "    predicted_positive = (probabilities > t_value)\n",
        "    actual_positive = (ground_truth_labels == class_label_index)\n",
        "\n",
        "    self.TP = np.sum(predicted_positive & actual_positive)\n",
        "    self.TN = np.sum(~predicted_positive & ~actual_positive)\n",
        "    self.FP = np.sum(predicted_positive & ~actual_positive)\n",
        "    self.FN = np.sum(~predicted_positive & actual_positive)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve4mBkK4HU_U"
      },
      "outputs": [],
      "source": [
        "# class to calculate and store class statistics\n",
        "class Statistics(object):\n",
        "  def __init__(self, confusion_matrix: ConfusionMatrix) -> None:\n",
        "    self.class_name = confusion_matrix.class_name\n",
        "\n",
        "    self.ACCURACY = (confusion_matrix.TP + confusion_matrix.TN) / denominator if  (denominator:= confusion_matrix.TP + confusion_matrix.TN + confusion_matrix.FP + confusion_matrix.FN) > 0 else 0\n",
        "    self.PRECISION = confusion_matrix.TP / denominator if (denominator:= confusion_matrix.TP + confusion_matrix.FP) > 0 else 0\n",
        "    self.RECALL = confusion_matrix.TP / denominator if (denominator:= confusion_matrix.TP + confusion_matrix.FN) > 0 else 0\n",
        "    self.F1 = 2 * (self.PRECISION * self.RECALL) / denominator if (denominator:= self.PRECISION + self.RECALL) > 0 else 0\n",
        "\n",
        "  def __repr__(self) -> str:\n",
        "    return f\"Class {self.class_name} statistics:\\nAccuracy: {self.ACCURACY} \\nPrecision: {self.PRECISION}\\nRecall: {self.RECALL}\\nF1:{self.F1}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xDrfLK8JDsPb",
        "outputId": "9c859af0-b561-4e00-d338-d7861af3bbd2"
      },
      "outputs": [],
      "source": [
        "# download images\n",
        "Path(SAMPLE_IMAGES_ROOT_DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "sample_images_directories_by_class = download_dataset(dest_dir=SAMPLE_IMAGES_ROOT_DIRECTORY, class_labels=[label.capitalize() for label in IMAGENET_CLASS_INDEX_MAPPING.keys()], limit=NUMBER_OF_SAMPLE_IMAGES_PER_CLASS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5uzBthIpw2N"
      },
      "outputs": [],
      "source": [
        "# image transformations for RESNET50 model\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.Resize(256),\n",
        "        torchvision.transforms.CenterCrop(224),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMYItCfgqp7H"
      },
      "outputs": [],
      "source": [
        "# initialize dataset\n",
        "images_classes_by_directory: dict[str, str] = {images_directory[\"images_dir\"]: images_class for images_class, images_directory in sample_images_directories_by_class.items()}\n",
        "dataset: CustomDataset = CustomDataset(root_image_directory=SAMPLE_IMAGES_ROOT_DIRECTORY, images_classes_by_directory=images_classes_by_directory, image_label_index_mapping=IMAGENET_CLASS_INDEX_MAPPING, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V_B6xunrcXO"
      },
      "outputs": [],
      "source": [
        "# initialize dataloader\n",
        "dataloader: DataLoader = DataLoader(dataset=dataset, batch_size=16, shuffle=True, num_workers=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZLjCubEsYkR"
      },
      "outputs": [],
      "source": [
        "# initialize torch device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2U18XIT-sqdn"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "resnet_model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
        "resnet_model.to(device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2l6ta7ttUdy"
      },
      "outputs": [],
      "source": [
        "# evaluate model\n",
        "# initializes empty numpy arrays to store probabilities of each class and ground truth\n",
        "sample_images_classes_probabilities = np.empty((NUMBER_OF_SAMPLE_IMAGES_PER_CLASS*NUMBER_OF_SAMPLE_CLASSES,NUMBER_OF_SAMPLE_CLASSES))\n",
        "ground_truth_labels = np.empty((NUMBER_OF_SAMPLE_IMAGES_PER_CLASS*NUMBER_OF_SAMPLE_CLASSES), dtype=int)\n",
        "current_index = 0\n",
        "\n",
        "resnet_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  # extract indexes of classes we want to evaluate for\n",
        "  sample_images_classes_indexes: list[int] = [index for index in IMAGENET_CLASS_INDEX_MAPPING.values()]\n",
        "\n",
        "  for images, labels in dataloader:\n",
        "    images = images.to(device)\n",
        "    probabilities = torch.sigmoid(resnet_model(images)).cpu().numpy()\n",
        "\n",
        "    # extract probabilities only of classes we want to evaluate for\n",
        "    sample_classes_probabilities = probabilities[:, sample_images_classes_indexes]\n",
        "    batch_size = sample_classes_probabilities.shape[0]\n",
        "\n",
        "    # assign batch probabilities and ground truths to the complete array\n",
        "    sample_images_classes_probabilities[current_index:current_index + batch_size, :] = sample_classes_probabilities\n",
        "\n",
        "    ground_truth_labels[current_index:current_index + batch_size] = labels.cpu().numpy()\n",
        "\n",
        "    current_index += batch_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NVpLZSbSDOS"
      },
      "outputs": [],
      "source": [
        "# initialize confusion matrixes for each image sample class\n",
        "classes_confusion_matrixes = [ConfusionMatrix(class_name=class_name, class_label_index=imagenet_index, probabilities=sample_images_classes_probabilities[:, index], ground_truth_labels=ground_truth_labels, t_value=T_VALUES[index]) for index, (class_name, imagenet_index) in enumerate(IMAGENET_CLASS_INDEX_MAPPING.items())]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRsR-C8DV-8J"
      },
      "outputs": [],
      "source": [
        "# calculate statistics for each class\n",
        "classes_statistics = [Statistics(confusion_matrix) for confusion_matrix in classes_confusion_matrixes]\n",
        "print(classes_statistics)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
